{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m1rHK3ClqcEg"
      },
      "outputs": [],
      "source": [
        "### YOLOv8 docs: https://docs.ultralytics.com/tasks/classify/\n",
        "### Medical imaging example: https://github.com/sevdaimany/YOLOv8-Medical-Imaging/blob/master/classification/classify.py"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import sklearn.metrics\n",
        "from sklearn.metrics import roc_auc_score, roc_curve, confusion_matrix, ConfusionMatrixDisplay\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "RBLIex3GQRX3"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install ultralytics\n",
        "from ultralytics import YOLO"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TLbAyBiEHemL",
        "outputId": "020dd55c-b439-4b49-c26c-5556f2a3dccc"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting ultralytics\n",
            "  Downloading ultralytics-8.1.9-py3-none-any.whl (709 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m709.3/709.3 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: matplotlib>=3.3.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (3.7.1)\n",
            "Requirement already satisfied: numpy>=1.22.2 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (1.23.5)\n",
            "Requirement already satisfied: opencv-python>=4.6.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (4.8.0.76)\n",
            "Requirement already satisfied: pillow>=7.1.2 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (9.4.0)\n",
            "Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (6.0.1)\n",
            "Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.31.0)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (1.11.4)\n",
            "Requirement already satisfied: torch>=1.8.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.1.0+cu121)\n",
            "Requirement already satisfied: torchvision>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (0.16.0+cu121)\n",
            "Requirement already satisfied: tqdm>=4.64.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (4.66.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from ultralytics) (5.9.5)\n",
            "Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.10/dist-packages (from ultralytics) (9.0.0)\n",
            "Collecting thop>=0.1.1 (from ultralytics)\n",
            "  Downloading thop-0.1.1.post2209072238-py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: pandas>=1.1.4 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (1.5.3)\n",
            "Requirement already satisfied: seaborn>=0.11.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (0.13.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.2.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (4.47.2)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.4.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (23.2)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (3.1.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.4->ultralytics) (2023.4)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (2023.11.17)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (3.1.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (2023.6.0)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (2.1.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.8.0->ultralytics) (2.1.4)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.8.0->ultralytics) (1.3.0)\n",
            "Installing collected packages: thop, ultralytics\n",
            "Successfully installed thop-0.1.1.post2209072238 ultralytics-8.1.9\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "finetuned = 'RIM-ONE_PRC'\n",
        "data_path = '/content/drive/MyDrive/Thesis/' + finetuned + '_ROI/'\n",
        "\n",
        "# load model\n",
        "model = YOLO('yolov8n-cls.pt')"
      ],
      "metadata": {
        "id": "oEtjWVuEHsty"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_epochs = 100\n",
        "dim = 224\n",
        "\n",
        "# train on retinal images\n",
        "results = model.train(data=data_path, batch=32, epochs=num_epochs, imgsz=dim)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r1OR63kmIXrr",
        "outputId": "9c9266e9-a753-4914-ce14-4157edef5baa"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ultralytics YOLOv8.1.9 ðŸš€ Python-3.10.12 torch-2.1.0+cu121 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=classify, mode=train, model=yolov8n-cls.pt, data=/content/drive/MyDrive/Thesis/RIM-ONE_PRC_ROI/, epochs=100, time=None, patience=50, batch=32, imgsz=224, save=True, save_period=-1, cache=False, device=None, workers=8, project=None, name=train2, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=runs/classify/train2\n",
            "\u001b[34m\u001b[1mtrain:\u001b[0m /content/drive/MyDrive/Thesis/RIM-ONE_PRC_ROI/train... found 392 images in 2 classes âœ… \n",
            "\u001b[34m\u001b[1mval:\u001b[0m /content/drive/MyDrive/Thesis/RIM-ONE_PRC_ROI/val... found 49 images in 2 classes âœ… \n",
            "\u001b[34m\u001b[1mtest:\u001b[0m /content/drive/MyDrive/Thesis/RIM-ONE_PRC_ROI/test... found 49 images in 2 classes âœ… \n",
            "Overriding model.yaml nc=1000 with nc=2\n",
            "\n",
            "                   from  n    params  module                                       arguments                     \n",
            "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
            "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
            "  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n",
            "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
            "  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n",
            "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
            "  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
            "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
            "  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n",
            "  9                  -1  1    332802  ultralytics.nn.modules.head.Classify         [256, 2]                      \n",
            "YOLOv8n-cls summary: 99 layers, 1440850 parameters, 1440850 gradients, 3.4 GFLOPs\n",
            "Transferred 156/158 items from pretrained weights\n",
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/classify/train2', view at http://localhost:6006/\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/drive/MyDrive/Thesis/RIM-ONE_PRC_ROI/train... 392 images, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 392/392 [00:40<00:00,  9.78it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /content/drive/MyDrive/Thesis/RIM-ONE_PRC_ROI/train.cache\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/drive/MyDrive/Thesis/RIM-ONE_PRC_ROI/val... 49 images, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 49/49 [00:12<00:00,  3.86it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /content/drive/MyDrive/Thesis/RIM-ONE_PRC_ROI/val.cache\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.000714, momentum=0.9) with parameter groups 26 weight(decay=0.0), 27 weight(decay=0.0005), 27 bias(decay=0.0)\n",
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mmodel graph visualization added âœ…\n",
            "Image sizes 224 train, 224 val\n",
            "Using 2 dataloader workers\n",
            "Logging results to \u001b[1mruns/classify/train2\u001b[0m\n",
            "Starting training for 100 epochs...\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      1/100     0.713G     0.6753          8        224: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:03<00:00,  3.69it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.37it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all      0.612          1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      2/100     0.577G     0.6076          8        224: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:03<00:00,  3.86it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 16.44it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all      0.714          1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      3/100     0.577G     0.5262          8        224: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:04<00:00,  2.73it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 30.49it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all      0.837          1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      4/100     0.581G     0.4872          8        224: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:03<00:00,  3.25it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 59.83it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all      0.837          1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      5/100     0.577G     0.4292          8        224: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:04<00:00,  2.69it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 38.95it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all      0.816          1\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      6/100     0.581G     0.3891          8        224: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:05<00:00,  2.36it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 47.84it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all      0.857          1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      7/100     0.577G     0.3652          8        224: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:03<00:00,  3.30it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 32.34it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all      0.816          1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      8/100     0.581G     0.3015          8        224: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:05<00:00,  2.57it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 31.39it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all      0.816          1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      9/100     0.579G      0.252          8        224: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:04<00:00,  3.21it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 27.75it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all      0.776          1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     10/100     0.581G     0.2812          8        224: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:03<00:00,  3.33it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 40.14it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all      0.837          1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     11/100     0.577G      0.221          8        224: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:05<00:00,  2.48it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 39.41it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all      0.837          1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     12/100     0.581G     0.2559          8        224: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:03<00:00,  3.37it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 26.45it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all      0.857          1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     13/100     0.579G     0.1828          8        224: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:03<00:00,  3.43it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 39.17it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all      0.816          1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     14/100     0.581G     0.1796          8        224: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:05<00:00,  2.42it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 27.12it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all      0.857          1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     15/100     0.577G     0.1949          8        224: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:03<00:00,  3.53it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 50.23it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all      0.816          1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     16/100     0.581G     0.1205          8        224: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:04<00:00,  3.10it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 16.47it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all      0.816          1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     17/100     0.577G     0.1587          8        224: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:04<00:00,  2.71it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 59.87it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all      0.755          1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     18/100     0.581G     0.1217          8        224: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:03<00:00,  3.37it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 37.40it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all      0.816          1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     19/100     0.577G     0.1504          8        224: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:04<00:00,  2.78it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 17.07it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all      0.857          1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     20/100     0.581G     0.1046          8        224: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:03<00:00,  3.43it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 28.20it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all      0.857          1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     21/100     0.577G     0.1707          8        224: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:03<00:00,  3.32it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 56.30it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all      0.735          1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     22/100     0.581G     0.1698          8        224: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:05<00:00,  2.44it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 42.88it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all      0.837          1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     23/100     0.577G      0.107          8        224: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:03<00:00,  3.28it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 25.81it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all      0.837          1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     24/100     0.581G    0.09509          8        224: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:03<00:00,  3.37it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 39.56it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all      0.857          1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     25/100     0.577G    0.08876          8        224: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:05<00:00,  2.51it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 63.13it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all      0.796          1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     26/100     0.581G    0.07012          8        224: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:03<00:00,  3.28it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 54.56it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all      0.878          1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     27/100     0.577G     0.1216          8        224: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:03<00:00,  3.36it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 15.59it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all      0.878          1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     28/100     0.581G     0.1045          8        224: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:04<00:00,  2.75it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 54.10it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all      0.878          1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     29/100     0.577G     0.1232          8        224: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:03<00:00,  3.45it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 55.63it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all      0.796          1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     30/100     0.581G     0.1544          8        224: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:04<00:00,  2.97it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 16.62it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all      0.857          1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     31/100     0.577G     0.1001          8        224: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:04<00:00,  2.91it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 29.44it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all      0.837          1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     32/100     0.581G    0.07189          8        224: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:03<00:00,  3.35it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 48.95it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all      0.857          1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     33/100     0.577G    0.07478          8        224: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:05<00:00,  2.59it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 32.52it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all      0.878          1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     34/100     0.581G    0.05686          8        224: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:04<00:00,  3.21it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 34.69it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all      0.816          1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     35/100     0.577G     0.1015          8        224: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:03<00:00,  3.41it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 59.97it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all      0.816          1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     36/100     0.581G    0.09191          8        224: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:05<00:00,  2.42it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 30.75it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all      0.816          1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     37/100     0.577G     0.1063          8        224: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:03<00:00,  3.41it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 34.22it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all      0.857          1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     38/100     0.581G    0.07363          8        224: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:04<00:00,  3.24it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 58.49it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all      0.857          1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     39/100     0.577G    0.06185          8        224: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:05<00:00,  2.43it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 35.05it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all      0.837          1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     40/100     0.581G    0.08025          8        224: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:03<00:00,  3.40it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 26.74it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all      0.776          1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     41/100     0.577G    0.06233          8        224: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:04<00:00,  3.25it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 25.83it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all      0.796          1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     42/100     0.581G    0.08713          8        224: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:04<00:00,  2.62it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 23.83it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all      0.796          1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     43/100     0.577G    0.07848          8        224: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:03<00:00,  3.53it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 59.39it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all      0.755          1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     44/100     0.581G    0.05801          8        224: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:04<00:00,  2.93it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 27.50it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all      0.837          1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     45/100     0.577G    0.07883          8        224: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:04<00:00,  2.81it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 42.69it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all      0.857          1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     46/100     0.581G     0.0467          8        224: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:04<00:00,  3.24it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 48.24it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all      0.837          1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     47/100     0.577G    0.05638          8        224: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:05<00:00,  2.55it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 33.46it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all      0.857          1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     48/100     0.581G    0.02682          8        224: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:04<00:00,  3.05it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 24.78it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all      0.857          1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     49/100     0.577G    0.05458          8        224: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:03<00:00,  3.42it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 51.89it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all      0.878          1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     50/100     0.581G    0.04359          8        224: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:05<00:00,  2.58it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 62.03it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all      0.878          1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     51/100     0.577G    0.05648          8        224: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:03<00:00,  3.33it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 37.75it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all      0.878          1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     52/100     0.581G    0.02642          8        224: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:03<00:00,  3.27it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 47.47it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all      0.878          1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     53/100     0.577G     0.0694          8        224: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:04<00:00,  2.62it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 34.17it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all      0.898          1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     54/100     0.581G    0.04269          8        224: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:04<00:00,  3.25it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 60.25it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all      0.857          1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     55/100     0.577G    0.06021          8        224: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:04<00:00,  3.12it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 14.49it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all      0.878          1\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     56/100     0.581G    0.06391          8        224: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:04<00:00,  2.79it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 52.83it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all      0.857          1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     57/100     0.577G    0.04151          8        224: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:03<00:00,  3.36it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 27.32it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all      0.857          1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     58/100     0.581G    0.03012          8        224: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:04<00:00,  2.63it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 20.72it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all      0.857          1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     59/100     0.577G    0.02258          8        224: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:04<00:00,  3.24it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 26.86it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all      0.837          1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     60/100     0.581G    0.03675          8        224: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:04<00:00,  3.20it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 28.37it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all      0.857          1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     61/100     0.579G    0.08254          8        224: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:05<00:00,  2.44it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 61.37it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all      0.857          1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     62/100     0.581G    0.07062          8        224: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:04<00:00,  3.23it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 32.09it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all      0.878          1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     63/100     0.577G    0.04044          8        224: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:03<00:00,  3.32it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 31.66it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all      0.816          1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     64/100     0.581G    0.04089          8        224: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:05<00:00,  2.48it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 39.23it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all      0.816          1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     65/100     0.577G    0.09277          8        224: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:03<00:00,  3.39it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 50.91it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all      0.816          1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     66/100     0.581G    0.04221          8        224: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:03<00:00,  3.32it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 24.12it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all      0.857          1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     67/100     0.577G    0.03032          8        224: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:05<00:00,  2.54it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 53.59it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all      0.837          1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     68/100     0.581G    0.03303          8        224: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:03<00:00,  3.31it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 45.90it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all      0.837          1\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     69/100     0.577G    0.05336          8        224: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:04<00:00,  3.05it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 13.05it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all      0.878          1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     70/100     0.581G    0.03022          8        224: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:04<00:00,  2.87it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 62.73it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all      0.857          1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     71/100     0.577G    0.02529          8        224: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:03<00:00,  3.32it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 47.83it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all      0.837          1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     72/100     0.581G    0.04476          8        224: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:05<00:00,  2.55it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 30.82it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all      0.837          1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     73/100     0.577G     0.0271          8        224: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:03<00:00,  3.28it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 51.02it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all      0.816          1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     74/100     0.581G    0.04224          8        224: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:04<00:00,  3.20it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 34.53it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all      0.837          1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     75/100     0.577G    0.02438          8        224: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:05<00:00,  2.56it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 49.13it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all      0.816          1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     76/100     0.581G    0.02708          8        224: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:04<00:00,  3.17it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 29.89it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all      0.816          1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     77/100     0.577G    0.05523          8        224: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:03<00:00,  3.30it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 48.35it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all      0.816          1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     78/100     0.581G    0.03644          8        224: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:05<00:00,  2.41it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 42.53it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all      0.816          1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     79/100     0.577G    0.03264          8        224: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:03<00:00,  3.36it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 24.73it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all      0.837          1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     80/100     0.581G    0.03258          8        224: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:05<00:00,  2.35it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 19.57it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all      0.776          1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     81/100     0.577G    0.02699          8        224: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:05<00:00,  2.58it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 44.55it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all      0.776          1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     82/100     0.581G    0.02905          8        224: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:03<00:00,  3.36it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 38.83it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all      0.776          1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     83/100     0.579G    0.04172          8        224: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:04<00:00,  2.84it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 17.57it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all      0.816          1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     84/100     0.581G    0.09166          8        224: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:04<00:00,  2.91it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 45.70it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all      0.837          1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     85/100     0.577G    0.04475          8        224: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:03<00:00,  3.42it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 33.67it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all      0.878          1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     86/100     0.581G    0.04993          8        224: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:05<00:00,  2.43it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 54.44it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all      0.878          1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     87/100     0.577G     0.0183          8        224: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:03<00:00,  3.38it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 51.61it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all      0.857          1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     88/100     0.581G      0.034          8        224: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:04<00:00,  3.23it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 42.66it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all      0.837          1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     89/100     0.577G    0.01976          8        224: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:05<00:00,  2.46it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 51.69it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all      0.837          1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     90/100     0.581G      0.049          8        224: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:04<00:00,  3.23it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 31.97it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all      0.837          1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     91/100     0.577G    0.02512          8        224: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:04<00:00,  2.65it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 17.34it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all      0.837          1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     92/100     0.581G    0.05555          8        224: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:04<00:00,  2.98it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 19.42it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all      0.857          1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     93/100     0.579G    0.03369          8        224: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:03<00:00,  3.27it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 24.04it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all      0.837          1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     94/100     0.581G    0.01899          8        224: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:05<00:00,  2.44it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 59.74it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all      0.796          1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     95/100     0.577G      0.049          8        224: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:04<00:00,  3.15it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 23.89it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all      0.816          1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     96/100     0.581G    0.04619          8        224: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:04<00:00,  3.12it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 53.87it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all      0.796          1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     97/100     0.577G    0.02037          8        224: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:05<00:00,  2.42it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 41.47it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all      0.816          1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     98/100     0.581G    0.02572          8        224: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:03<00:00,  3.29it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 59.18it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all      0.816          1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     99/100     0.577G    0.05121          8        224: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:03<00:00,  3.32it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 17.86it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all      0.816          1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "    100/100     0.581G    0.02237          8        224: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:04<00:00,  2.71it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 52.67it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all      0.816          1\n",
            "\n",
            "100 epochs completed in 0.138 hours.\n",
            "Optimizer stripped from runs/classify/train2/weights/last.pt, 3.0MB\n",
            "Optimizer stripped from runs/classify/train2/weights/best.pt, 3.0MB\n",
            "\n",
            "Validating runs/classify/train2/weights/best.pt...\n",
            "Ultralytics YOLOv8.1.9 ðŸš€ Python-3.10.12 torch-2.1.0+cu121 CUDA:0 (Tesla T4, 15102MiB)\n",
            "YOLOv8n-cls summary (fused): 73 layers, 1437442 parameters, 0 gradients, 3.3 GFLOPs\n",
            "\u001b[34m\u001b[1mtrain:\u001b[0m /content/drive/MyDrive/Thesis/RIM-ONE_PRC_ROI/train... found 392 images in 2 classes âœ… \n",
            "\u001b[34m\u001b[1mval:\u001b[0m /content/drive/MyDrive/Thesis/RIM-ONE_PRC_ROI/val... found 49 images in 2 classes âœ… \n",
            "\u001b[34m\u001b[1mtest:\u001b[0m /content/drive/MyDrive/Thesis/RIM-ONE_PRC_ROI/test... found 49 images in 2 classes âœ… \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "               classes   top1_acc   top5_acc: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 32.32it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all      0.898          1\n",
            "Speed: 0.1ms preprocess, 0.2ms inference, 0.0ms loss, 0.0ms postprocess per image\n",
            "Results saved to \u001b[1mruns/classify/train2\u001b[0m\n",
            "Results saved to \u001b[1mruns/classify/train2\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "------------------------------------------------------------\n",
        "**Testing with finetuned model**"
      ],
      "metadata": {
        "id": "5WtIIczprab_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# dictionary of best finetuned models\n",
        "paths = {'ACRIMA': '/content/drive/MyDrive/Thesis/trained_models/YOLOv8_ACRIMA_100eps_Jan26.pt',\n",
        "         'ORIGA': '/content/drive/MyDrive/Thesis/trained_models/YOLOv8_ORIGA_100eps_Jan26.pt',\n",
        "         'REFUGE': '/content/drive/MyDrive/Thesis/trained_models/YOLOv8_REFUGE_100eps_Jan26.pt',\n",
        "         'RIM-ONE': '/content/drive/MyDrive/Thesis/trained_models/YOLOv8_RIM-ONE_100eps_Jan26.pt',\n",
        "         'ACRIMA_PRC': '/content/drive/MyDrive/Thesis/trained_models/YOLOv8_ACRIMA_PRC_100eps_Feb3.pt',\n",
        "         'ORIGA_PRC': '/content/drive/MyDrive/Thesis/trained_models/YOLOv8_ORIGA_PRC_100eps_Feb3.pt',\n",
        "         'REFUGE_PRC': '/content/drive/MyDrive/Thesis/trained_models/YOLOv8_REFUGE_PRC_100eps_Feb3.pt',\n",
        "         'RIM-ONE_PRC': '/content/drive/MyDrive/Thesis/trained_models/YOLOv8_RIM-ONE_PRC_100eps_Feb3.pt'}"
      ],
      "metadata": {
        "id": "dMo0g5qxtsWZ"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# load model with best training weights\n",
        "finetuned = 'RIM-ONE_PRC'\n",
        "best_path = paths[finetuned]\n",
        "model = YOLO(best_path)"
      ],
      "metadata": {
        "id": "3A4k_TLxOBjb"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# function to test model and get AUC score, ROC metrics\n",
        "def collect_auc_roc(labels_list, softmax_list):\n",
        "\n",
        "    # calculate AUC score, FPR and TPR rates for ROC curve from labels and softmax predictions\n",
        "\n",
        "    score = roc_auc_score(labels_list, softmax_list)\n",
        "    fpr, tpr, _ = roc_curve(labels_list, softmax_list, pos_label = '1')\n",
        "\n",
        "    return score, fpr, tpr\n",
        "\n",
        "# function to get confusion matrix metrics from predictions and labels\n",
        "def acc_and_confusion(preds_list, labels_list):\n",
        "    tp = 0\n",
        "    tn = 0\n",
        "    fp = 0\n",
        "    fn = 0\n",
        "    total = len(preds_list)\n",
        "\n",
        "    for i in range(len(preds_list)):\n",
        "        # correct class\n",
        "        if preds_list[i] == labels_list[i]:\n",
        "            if preds_list[i] == '1' and labels_list[i] == '1': tp += 1\n",
        "            elif preds_list[i] == '0' and labels_list[i] == '0': tn += 1\n",
        "            # ensure all predictions are sorted\n",
        "            else: print(\"equal not true\")\n",
        "\n",
        "        # incorrect class\n",
        "        if preds_list[i] != labels_list[i]:\n",
        "            if preds_list[i] == '1' and labels_list[i] == '0': fp += 1\n",
        "            elif preds_list[i] == '0' and labels_list[i] == '1': fn += 1\n",
        "            # ensure all predictions are sorted\n",
        "            else: print(\"unequal not true\")\n",
        "\n",
        "    # calculate accuracy\n",
        "    acc = (tp + tn) / total\n",
        "    assert total == tp+tn+fp+fn\n",
        "\n",
        "    return acc, tp, tn, fp, fn"
      ],
      "metadata": {
        "id": "L7OloGAEUw83"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# TEST ON ALL DATASETS\n",
        "test_sets = ['ACRIMA_PRC', 'ORIGA_PRC', 'REFUGE_PRC', 'RIM-ONE_PRC']\n",
        "\n",
        "colors = ['green', 'orange', 'red', 'blue']\n",
        "\n",
        "# create empty figure\n",
        "plt.figure()\n",
        "i = 0\n",
        "\n",
        "for test_set in test_sets:\n",
        "  test_path = '/content/drive/MyDrive/Thesis/' + test_set + '_ROI/test/'\n",
        "\n",
        "  print(\"Loading for: \", test_set)\n",
        "\n",
        "  labels_list = []\n",
        "  preds_list = []\n",
        "  softmax_list = []\n",
        "\n",
        "  for cls in ['0', '1']:\n",
        "    label = cls\n",
        "    path = test_path + cls + '/'\n",
        "\n",
        "    for filename in os.listdir(path):\n",
        "      img = path + filename\n",
        "      results = model.predict(img, imgsz=224)\n",
        "      result = results[0]\n",
        "\n",
        "      class_names = result.names\n",
        "      probs = result.probs.data.tolist()\n",
        "      pred = class_names[np.argmax(probs)].upper()\n",
        "\n",
        "      labels_list += [label]\n",
        "      preds_list += [pred]\n",
        "      softmax_list += [probs[1]]\n",
        "\n",
        "  acc, tp, tn, fp, fn = acc_and_confusion(preds_list, labels_list)\n",
        "  print(\"Accuracy: \", acc)\n",
        "  print(\"TP: \", tp)\n",
        "  print(\"TN: \", tn)\n",
        "  print(\"FP: \", fp)\n",
        "  print(\"FN: \", fn)\n",
        "\n",
        "  score, fpr, tpr = collect_auc_roc(labels_list, softmax_list)\n",
        "\n",
        "  print(\"AUC score: \" + str(score))\n",
        "\n",
        "  # add ROC curve to plot for each test set\n",
        "  plt.plot(fpr, tpr, label=test_set + \" (AUC = \" + str(round(score,2)) + \")\", color=colors[i])\n",
        "  i += 1\n",
        "\n",
        "  print(\" \")\n",
        "\n",
        "# show and save plot with all 4 test set curves\n",
        "plt.xlabel(\"False Positive Rate\")\n",
        "plt.ylabel(\"True Positive Rate\")\n",
        "plt.title(\"ROC Curves for \" + finetuned + \"-Trained Model\")\n",
        "plt.legend()\n",
        "plt.savefig('/content/drive/MyDrive/Thesis/ROC curve plots/' + finetuned + '_YOLOv8_100eps_ROC_curve.png')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "E2dUHp6cPNB8",
        "outputId": "2328cff0-fba2-4959-904b-fc8d5dc13005"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading for:  ACRIMA_PRC\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Thesis/ACRIMA_PRC_ROI/test/0/Im003_ACRIMA.jpg: 224x224 1 0.99, 0 0.01, 2.9ms\n",
            "Speed: 54.5ms preprocess, 2.9ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 224)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Thesis/ACRIMA_PRC_ROI/test/0/Im005_ACRIMA.jpg: 224x224 1 0.52, 0 0.48, 3.3ms\n",
            "Speed: 3.5ms preprocess, 3.3ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 224)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Thesis/ACRIMA_PRC_ROI/test/0/Im017_ACRIMA.jpg: 224x224 1 0.70, 0 0.30, 2.9ms\n",
            "Speed: 1.9ms preprocess, 2.9ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 224)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Thesis/ACRIMA_PRC_ROI/test/0/Im075_ACRIMA.jpg: 224x224 0 0.70, 1 0.30, 2.9ms\n",
            "Speed: 2.1ms preprocess, 2.9ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 224)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Thesis/ACRIMA_PRC_ROI/test/0/Im076_ACRIMA.jpg: 224x224 1 0.62, 0 0.38, 2.9ms\n",
            "Speed: 2.1ms preprocess, 2.9ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 224)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Thesis/ACRIMA_PRC_ROI/test/0/Im080_ACRIMA.jpg: 224x224 0 0.65, 1 0.35, 2.9ms\n",
            "Speed: 2.7ms preprocess, 2.9ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 224)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Thesis/ACRIMA_PRC_ROI/test/0/Im086_ACRIMA.jpg: 224x224 1 0.85, 0 0.15, 2.9ms\n",
            "Speed: 2.3ms preprocess, 2.9ms inference, 0.1ms postprocess per image at shape (1, 3, 224, 224)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Thesis/ACRIMA_PRC_ROI/test/0/Im088_ACRIMA.jpg: 224x224 0 0.96, 1 0.04, 2.9ms\n",
            "Speed: 2.2ms preprocess, 2.9ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 224)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Thesis/ACRIMA_PRC_ROI/test/0/Im129_ACRIMA.jpg: 224x224 1 0.84, 0 0.16, 2.9ms\n",
            "Speed: 2.0ms preprocess, 2.9ms inference, 0.1ms postprocess per image at shape (1, 3, 224, 224)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Thesis/ACRIMA_PRC_ROI/test/0/Im136_ACRIMA.jpg: 224x224 0 0.73, 1 0.27, 2.9ms\n",
            "Speed: 2.1ms preprocess, 2.9ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 224)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Thesis/ACRIMA_PRC_ROI/test/0/Im141_ACRIMA.jpg: 224x224 0 0.75, 1 0.25, 4.8ms\n",
            "Speed: 3.1ms preprocess, 4.8ms inference, 0.1ms postprocess per image at shape (1, 3, 224, 224)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Thesis/ACRIMA_PRC_ROI/test/0/Im147_ACRIMA.jpg: 224x224 1 0.84, 0 0.16, 4.5ms\n",
            "Speed: 2.9ms preprocess, 4.5ms inference, 0.1ms postprocess per image at shape (1, 3, 224, 224)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Thesis/ACRIMA_PRC_ROI/test/0/Im152_ACRIMA.jpg: 224x224 0 0.81, 1 0.19, 8.9ms\n",
            "Speed: 3.0ms preprocess, 8.9ms inference, 0.1ms postprocess per image at shape (1, 3, 224, 224)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Thesis/ACRIMA_PRC_ROI/test/0/Im159_ACRIMA.jpg: 224x224 0 0.83, 1 0.17, 10.9ms\n",
            "Speed: 2.9ms preprocess, 10.9ms inference, 0.1ms postprocess per image at shape (1, 3, 224, 224)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Thesis/ACRIMA_PRC_ROI/test/0/Im166_ACRIMA.jpg: 224x224 1 0.51, 0 0.49, 4.6ms\n",
            "Speed: 4.2ms preprocess, 4.6ms inference, 0.1ms postprocess per image at shape (1, 3, 224, 224)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Thesis/ACRIMA_PRC_ROI/test/0/Im180_ACRIMA.jpg: 224x224 0 0.95, 1 0.05, 8.8ms\n",
            "Speed: 2.9ms preprocess, 8.8ms inference, 0.1ms postprocess per image at shape (1, 3, 224, 224)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Thesis/ACRIMA_PRC_ROI/test/0/Im187_ACRIMA.jpg: 224x224 1 0.74, 0 0.26, 5.4ms\n",
            "Speed: 3.0ms preprocess, 5.4ms inference, 0.1ms postprocess per image at shape (1, 3, 224, 224)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Thesis/ACRIMA_PRC_ROI/test/0/Im199_ACRIMA.jpg: 224x224 1 0.98, 0 0.02, 6.1ms\n",
            "Speed: 2.7ms preprocess, 6.1ms inference, 0.1ms postprocess per image at shape (1, 3, 224, 224)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Thesis/ACRIMA_PRC_ROI/test/0/Im203_ACRIMA.jpg: 224x224 0 0.99, 1 0.01, 5.8ms\n",
            "Speed: 2.9ms preprocess, 5.8ms inference, 0.1ms postprocess per image at shape (1, 3, 224, 224)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Thesis/ACRIMA_PRC_ROI/test/0/Im237_ACRIMA.jpg: 224x224 1 0.58, 0 0.42, 6.0ms\n",
            "Speed: 4.7ms preprocess, 6.0ms inference, 0.1ms postprocess per image at shape (1, 3, 224, 224)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Thesis/ACRIMA_PRC_ROI/test/0/Im245_ACRIMA.jpg: 224x224 1 0.59, 0 0.41, 17.6ms\n",
            "Speed: 2.9ms preprocess, 17.6ms inference, 0.1ms postprocess per image at shape (1, 3, 224, 224)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Thesis/ACRIMA_PRC_ROI/test/0/Im249_ACRIMA.jpg: 224x224 0 0.59, 1 0.41, 11.7ms\n",
            "Speed: 2.8ms preprocess, 11.7ms inference, 0.1ms postprocess per image at shape (1, 3, 224, 224)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Thesis/ACRIMA_PRC_ROI/test/0/Im255_ACRIMA.jpg: 224x224 1 0.79, 0 0.21, 3.1ms\n",
            "Speed: 2.5ms preprocess, 3.1ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 224)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Thesis/ACRIMA_PRC_ROI/test/0/Im262_ACRIMA.jpg: 224x224 0 0.97, 1 0.03, 3.3ms\n",
            "Speed: 2.6ms preprocess, 3.3ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 224)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Thesis/ACRIMA_PRC_ROI/test/0/Im283_ACRIMA.jpg: 224x224 0 0.99, 1 0.01, 2.9ms\n",
            "Speed: 2.1ms preprocess, 2.9ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 224)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Thesis/ACRIMA_PRC_ROI/test/0/Im288_ACRIMA.jpg: 224x224 0 0.68, 1 0.32, 3.9ms\n",
            "Speed: 2.9ms preprocess, 3.9ms inference, 0.1ms postprocess per image at shape (1, 3, 224, 224)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Thesis/ACRIMA_PRC_ROI/test/1/Im341_g_ACRIMA.jpg: 224x224 1 0.99, 0 0.01, 4.7ms\n",
            "Speed: 3.4ms preprocess, 4.7ms inference, 0.1ms postprocess per image at shape (1, 3, 224, 224)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Thesis/ACRIMA_PRC_ROI/test/1/Im344_g_ACRIMA.jpg: 224x224 1 1.00, 0 0.00, 4.8ms\n",
            "Speed: 3.9ms preprocess, 4.8ms inference, 0.1ms postprocess per image at shape (1, 3, 224, 224)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Thesis/ACRIMA_PRC_ROI/test/1/Im352_g_ACRIMA.jpg: 224x224 1 0.97, 0 0.03, 5.0ms\n",
            "Speed: 2.9ms preprocess, 5.0ms inference, 0.1ms postprocess per image at shape (1, 3, 224, 224)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Thesis/ACRIMA_PRC_ROI/test/1/Im356_g_ACRIMA.jpg: 224x224 1 0.97, 0 0.03, 2.9ms\n",
            "Speed: 2.1ms preprocess, 2.9ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 224)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Thesis/ACRIMA_PRC_ROI/test/1/Im367_g_ACRIMA.jpg: 224x224 1 0.93, 0 0.07, 3.1ms\n",
            "Speed: 2.5ms preprocess, 3.1ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 224)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Thesis/ACRIMA_PRC_ROI/test/1/Im368_g_ACRIMA.jpg: 224x224 1 1.00, 0 0.00, 5.1ms\n",
            "Speed: 2.9ms preprocess, 5.1ms inference, 0.1ms postprocess per image at shape (1, 3, 224, 224)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Thesis/ACRIMA_PRC_ROI/test/1/Im372_g_ACRIMA.jpg: 224x224 1 0.92, 0 0.08, 2.9ms\n",
            "Speed: 1.8ms preprocess, 2.9ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 224)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Thesis/ACRIMA_PRC_ROI/test/1/Im371_g_ACRIMA.jpg: 224x224 1 0.99, 0 0.01, 3.1ms\n",
            "Speed: 2.1ms preprocess, 3.1ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 224)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Thesis/ACRIMA_PRC_ROI/test/1/Im378_g_ACRIMA.jpg: 224x224 1 0.99, 0 0.01, 3.2ms\n",
            "Speed: 2.0ms preprocess, 3.2ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 224)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Thesis/ACRIMA_PRC_ROI/test/1/Im388_g_ACRIMA.jpg: 224x224 1 0.99, 0 0.01, 2.8ms\n",
            "Speed: 1.9ms preprocess, 2.8ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 224)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Thesis/ACRIMA_PRC_ROI/test/1/Im390_g_ACRIMA.jpg: 224x224 0 0.86, 1 0.14, 3.1ms\n",
            "Speed: 2.1ms preprocess, 3.1ms inference, 0.1ms postprocess per image at shape (1, 3, 224, 224)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Thesis/ACRIMA_PRC_ROI/test/1/Im394_g_ACRIMA.jpg: 224x224 0 0.53, 1 0.47, 4.1ms\n",
            "Speed: 2.7ms preprocess, 4.1ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 224)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Thesis/ACRIMA_PRC_ROI/test/1/Im398_g_ACRIMA.jpg: 224x224 1 1.00, 0 0.00, 4.8ms\n",
            "Speed: 2.1ms preprocess, 4.8ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 224)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Thesis/ACRIMA_PRC_ROI/test/1/Im399_g_ACRIMA.jpg: 224x224 1 0.98, 0 0.02, 3.4ms\n",
            "Speed: 2.7ms preprocess, 3.4ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 224)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Thesis/ACRIMA_PRC_ROI/test/1/Im408_g_ACRIMA.jpg: 224x224 1 0.96, 0 0.04, 2.8ms\n",
            "Speed: 2.0ms preprocess, 2.8ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 224)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Thesis/ACRIMA_PRC_ROI/test/1/Im423_g_ACRIMA.jpg: 224x224 1 0.94, 0 0.06, 3.0ms\n",
            "Speed: 2.1ms preprocess, 3.0ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 224)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Thesis/ACRIMA_PRC_ROI/test/1/Im426_g_ACRIMA.jpg: 224x224 1 0.80, 0 0.20, 3.2ms\n",
            "Speed: 2.0ms preprocess, 3.2ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 224)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Thesis/ACRIMA_PRC_ROI/test/1/Im436_g_ACRIMA.jpg: 224x224 1 1.00, 0 0.00, 2.8ms\n",
            "Speed: 1.8ms preprocess, 2.8ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 224)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Thesis/ACRIMA_PRC_ROI/test/1/Im440_g_ACRIMA.jpg: 224x224 1 1.00, 0 0.00, 2.9ms\n",
            "Speed: 2.1ms preprocess, 2.9ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 224)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Thesis/ACRIMA_PRC_ROI/test/1/Im441_g_ACRIMA.jpg: 224x224 1 0.77, 0 0.23, 2.9ms\n",
            "Speed: 2.0ms preprocess, 2.9ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 224)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Thesis/ACRIMA_PRC_ROI/test/1/Im466_g_ACRIMA.jpg: 224x224 1 0.97, 0 0.03, 2.8ms\n",
            "Speed: 1.8ms preprocess, 2.8ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 224)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Thesis/ACRIMA_PRC_ROI/test/1/Im484_g_ACRIMA.jpg: 224x224 0 0.82, 1 0.18, 2.9ms\n",
            "Speed: 2.0ms preprocess, 2.9ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 224)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Thesis/ACRIMA_PRC_ROI/test/1/Im493_g_ACRIMA.jpg: 224x224 0 0.98, 1 0.02, 3.1ms\n",
            "Speed: 2.7ms preprocess, 3.1ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 224)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Thesis/ACRIMA_PRC_ROI/test/1/Im501_g_ACRIMA.jpg: 224x224 0 0.93, 1 0.07, 2.7ms\n",
            "Speed: 1.7ms preprocess, 2.7ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 224)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Thesis/ACRIMA_PRC_ROI/test/1/Im502_g_ACRIMA.jpg: 224x224 1 1.00, 0 0.00, 2.9ms\n",
            "Speed: 2.3ms preprocess, 2.9ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 224)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Thesis/ACRIMA_PRC_ROI/test/1/Im510_g_ACRIMA.jpg: 224x224 0 0.62, 1 0.38, 2.9ms\n",
            "Speed: 2.0ms preprocess, 2.9ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 224)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Thesis/ACRIMA_PRC_ROI/test/1/Im518_g_ACRIMA.jpg: 224x224 1 0.96, 0 0.04, 3.0ms\n",
            "Speed: 2.5ms preprocess, 3.0ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 224)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Thesis/ACRIMA_PRC_ROI/test/1/Im520_g_ACRIMA.jpg: 224x224 1 0.98, 0 0.02, 2.9ms\n",
            "Speed: 2.1ms preprocess, 2.9ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 224)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Thesis/ACRIMA_PRC_ROI/test/1/Im528_g_ACRIMA.jpg: 224x224 1 0.99, 0 0.01, 2.9ms\n",
            "Speed: 2.2ms preprocess, 2.9ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 224)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Thesis/ACRIMA_PRC_ROI/test/1/Im531_g_ACRIMA.jpg: 224x224 1 0.99, 0 0.01, 3.1ms\n",
            "Speed: 2.4ms preprocess, 3.1ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 224)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Thesis/ACRIMA_PRC_ROI/test/1/Im534_g_ACRIMA.jpg: 224x224 1 1.00, 0 0.00, 3.2ms\n",
            "Speed: 2.4ms preprocess, 3.2ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 224)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Thesis/ACRIMA_PRC_ROI/test/1/Im539_g_ACRIMA.jpg: 224x224 0 0.93, 1 0.07, 4.7ms\n",
            "Speed: 2.7ms preprocess, 4.7ms inference, 0.1ms postprocess per image at shape (1, 3, 224, 224)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Thesis/ACRIMA_PRC_ROI/test/1/Im545_g_ACRIMA.jpg: 224x224 0 0.97, 1 0.03, 3.8ms\n",
            "Speed: 2.8ms preprocess, 3.8ms inference, 0.1ms postprocess per image at shape (1, 3, 224, 224)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Thesis/ACRIMA_PRC_ROI/test/1/Im548_g_ACRIMA.jpg: 224x224 1 1.00, 0 0.00, 4.4ms\n",
            "Speed: 2.8ms preprocess, 4.4ms inference, 0.1ms postprocess per image at shape (1, 3, 224, 224)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Thesis/ACRIMA_PRC_ROI/test/1/Im570_g_ACRIMA.jpg: 224x224 1 0.99, 0 0.01, 3.7ms\n",
            "Speed: 2.6ms preprocess, 3.7ms inference, 0.1ms postprocess per image at shape (1, 3, 224, 224)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Thesis/ACRIMA_PRC_ROI/test/1/Im576_g_ACRIMA.jpg: 224x224 1 0.96, 0 0.04, 5.0ms\n",
            "Speed: 2.8ms preprocess, 5.0ms inference, 0.1ms postprocess per image at shape (1, 3, 224, 224)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Thesis/ACRIMA_PRC_ROI/test/1/Im592_g_ACRIMA.jpg: 224x224 0 0.57, 1 0.43, 3.0ms\n",
            "Speed: 2.4ms preprocess, 3.0ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 224)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Thesis/ACRIMA_PRC_ROI/test/1/Im599_g_ACRIMA.jpg: 224x224 1 0.73, 0 0.27, 3.0ms\n",
            "Speed: 2.1ms preprocess, 3.0ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 224)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Thesis/ACRIMA_PRC_ROI/test/1/Im617_g_ACRIMA.jpg: 224x224 1 1.00, 0 0.00, 2.8ms\n",
            "Speed: 1.9ms preprocess, 2.8ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 224)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Thesis/ACRIMA_PRC_ROI/test/1/Im624_g_ACRIMA.jpg: 224x224 1 0.85, 0 0.15, 2.9ms\n",
            "Speed: 2.0ms preprocess, 2.9ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 224)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Thesis/ACRIMA_PRC_ROI/test/1/Im633_g_ACRIMA.jpg: 224x224 1 1.00, 0 0.00, 2.8ms\n",
            "Speed: 1.8ms preprocess, 2.8ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 224)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Thesis/ACRIMA_PRC_ROI/test/1/Im670_g_ACRIMA.jpg: 224x224 1 1.00, 0 0.00, 2.9ms\n",
            "Speed: 2.0ms preprocess, 2.9ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 224)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Thesis/ACRIMA_PRC_ROI/test/1/Im673_g_ACRIMA.jpg: 224x224 0 0.85, 1 0.15, 3.0ms\n",
            "Speed: 2.2ms preprocess, 3.0ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 224)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Thesis/ACRIMA_PRC_ROI/test/1/Im697_g_ACRIMA.jpg: 224x224 1 1.00, 0 0.00, 2.9ms\n",
            "Speed: 2.0ms preprocess, 2.9ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 224)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Thesis/ACRIMA_PRC_ROI/test/1/Im699_g_ACRIMA.jpg: 224x224 0 0.80, 1 0.20, 3.4ms\n",
            "Speed: 2.5ms preprocess, 3.4ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 224)\n",
            "Accuracy:  0.6619718309859155\n",
            "TP:  34\n",
            "TN:  13\n",
            "FP:  13\n",
            "FN:  11\n",
            "AUC score: 0.7786324786324786\n",
            " \n",
            "Loading for:  ORIGA_PRC\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Thesis/ORIGA_PRC_ROI/test/0/001.jpg: 224x224 1 1.00, 0 0.00, 3.0ms\n",
            "Speed: 2.2ms preprocess, 3.0ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 224)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Thesis/ORIGA_PRC_ROI/test/0/012.jpg: 224x224 1 0.63, 0 0.37, 2.9ms\n",
            "Speed: 1.9ms preprocess, 2.9ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 224)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Thesis/ORIGA_PRC_ROI/test/0/014.jpg: 224x224 0 1.00, 1 0.00, 3.0ms\n",
            "Speed: 2.0ms preprocess, 3.0ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 224)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Thesis/ORIGA_PRC_ROI/test/0/026.jpg: 224x224 1 0.65, 0 0.35, 2.8ms\n",
            "Speed: 1.7ms preprocess, 2.8ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 224)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Thesis/ORIGA_PRC_ROI/test/0/031.jpg: 224x224 1 0.91, 0 0.09, 3.2ms\n",
            "Speed: 2.3ms preprocess, 3.2ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 224)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Thesis/ORIGA_PRC_ROI/test/0/009.jpg: 224x224 1 0.93, 0 0.07, 2.9ms\n",
            "Speed: 1.8ms preprocess, 2.9ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 224)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Thesis/ORIGA_PRC_ROI/test/0/011.jpg: 224x224 1 0.73, 0 0.27, 2.8ms\n",
            "Speed: 1.7ms preprocess, 2.8ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 224)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Thesis/ORIGA_PRC_ROI/test/0/048.jpg: 224x224 0 0.76, 1 0.24, 3.2ms\n",
            "Speed: 2.7ms preprocess, 3.2ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 224)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Thesis/ORIGA_PRC_ROI/test/0/083.jpg: 224x224 1 0.97, 0 0.03, 2.9ms\n",
            "Speed: 1.8ms preprocess, 2.9ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 224)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Thesis/ORIGA_PRC_ROI/test/0/105.jpg: 224x224 1 0.99, 0 0.01, 2.8ms\n",
            "Speed: 2.2ms preprocess, 2.8ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 224)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Thesis/ORIGA_PRC_ROI/test/0/085.jpg: 224x224 0 0.97, 1 0.03, 2.9ms\n",
            "Speed: 2.0ms preprocess, 2.9ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 224)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Thesis/ORIGA_PRC_ROI/test/0/096.jpg: 224x224 0 0.93, 1 0.07, 3.0ms\n",
            "Speed: 2.5ms preprocess, 3.0ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 224)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Thesis/ORIGA_PRC_ROI/test/0/091.jpg: 224x224 1 0.66, 0 0.34, 2.9ms\n",
            "Speed: 1.9ms preprocess, 2.9ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 224)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Thesis/ORIGA_PRC_ROI/test/0/098.jpg: 224x224 1 0.99, 0 0.01, 2.9ms\n",
            "Speed: 2.0ms preprocess, 2.9ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 224)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Thesis/ORIGA_PRC_ROI/test/0/119.jpg: 224x224 1 1.00, 0 0.00, 2.8ms\n",
            "Speed: 1.8ms preprocess, 2.8ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 224)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Thesis/ORIGA_PRC_ROI/test/0/121.jpg: 224x224 0 0.95, 1 0.05, 3.1ms\n",
            "Speed: 2.0ms preprocess, 3.1ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 224)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Thesis/ORIGA_PRC_ROI/test/0/118.jpg: 224x224 1 0.91, 0 0.09, 3.9ms\n",
            "Speed: 2.7ms preprocess, 3.9ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 224)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Thesis/ORIGA_PRC_ROI/test/0/114.jpg: 224x224 1 0.61, 0 0.39, 4.8ms\n",
            "Speed: 2.5ms preprocess, 4.8ms inference, 0.1ms postprocess per image at shape (1, 3, 224, 224)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Thesis/ORIGA_PRC_ROI/test/0/139.jpg: 224x224 0 0.81, 1 0.19, 3.9ms\n",
            "Speed: 2.6ms preprocess, 3.9ms inference, 0.1ms postprocess per image at shape (1, 3, 224, 224)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Thesis/ORIGA_PRC_ROI/test/0/136.jpg: 224x224 1 0.99, 0 0.01, 4.2ms\n",
            "Speed: 2.5ms preprocess, 4.2ms inference, 0.1ms postprocess per image at shape (1, 3, 224, 224)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Thesis/ORIGA_PRC_ROI/test/0/154.jpg: 224x224 0 0.79, 1 0.21, 4.8ms\n",
            "Speed: 2.7ms preprocess, 4.8ms inference, 0.1ms postprocess per image at shape (1, 3, 224, 224)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Thesis/ORIGA_PRC_ROI/test/0/170.jpg: 224x224 1 0.53, 0 0.47, 3.0ms\n",
            "Speed: 1.9ms preprocess, 3.0ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 224)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Thesis/ORIGA_PRC_ROI/test/0/230.jpg: 224x224 1 1.00, 0 0.00, 2.8ms\n",
            "Speed: 1.9ms preprocess, 2.8ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 224)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Thesis/ORIGA_PRC_ROI/test/0/217.jpg: 224x224 1 0.99, 0 0.01, 2.9ms\n",
            "Speed: 1.8ms preprocess, 2.9ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 224)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Thesis/ORIGA_PRC_ROI/test/0/254.jpg: 224x224 1 1.00, 0 0.00, 2.9ms\n",
            "Speed: 1.9ms preprocess, 2.9ms inference, 0.1ms postprocess per image at shape (1, 3, 224, 224)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Thesis/ORIGA_PRC_ROI/test/0/307.jpg: 224x224 1 0.78, 0 0.22, 2.9ms\n",
            "Speed: 2.0ms preprocess, 2.9ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 224)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Thesis/ORIGA_PRC_ROI/test/0/296.jpg: 224x224 0 0.89, 1 0.11, 4.0ms\n",
            "Speed: 2.2ms preprocess, 4.0ms inference, 0.1ms postprocess per image at shape (1, 3, 224, 224)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Thesis/ORIGA_PRC_ROI/test/0/308.jpg: 224x224 1 0.71, 0 0.29, 3.0ms\n",
            "Speed: 2.1ms preprocess, 3.0ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 224)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Thesis/ORIGA_PRC_ROI/test/0/324.jpg: 224x224 0 0.95, 1 0.05, 2.9ms\n",
            "Speed: 2.0ms preprocess, 2.9ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 224)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Thesis/ORIGA_PRC_ROI/test/0/325.jpg: 224x224 1 0.63, 0 0.37, 3.1ms\n",
            "Speed: 2.0ms preprocess, 3.1ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 224)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Thesis/ORIGA_PRC_ROI/test/0/372.jpg: 224x224 0 0.69, 1 0.31, 3.7ms\n",
            "Speed: 2.6ms preprocess, 3.7ms inference, 0.1ms postprocess per image at shape (1, 3, 224, 224)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Thesis/ORIGA_PRC_ROI/test/0/351.jpg: 224x224 0 0.90, 1 0.10, 2.9ms\n",
            "Speed: 1.9ms preprocess, 2.9ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 224)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Thesis/ORIGA_PRC_ROI/test/0/373.jpg: 224x224 1 0.98, 0 0.02, 2.8ms\n",
            "Speed: 1.8ms preprocess, 2.8ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 224)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Thesis/ORIGA_PRC_ROI/test/0/367.jpg: 224x224 1 1.00, 0 0.00, 2.8ms\n",
            "Speed: 1.8ms preprocess, 2.8ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 224)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Thesis/ORIGA_PRC_ROI/test/0/408.jpg: 224x224 0 1.00, 1 0.00, 2.9ms\n",
            "Speed: 2.0ms preprocess, 2.9ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 224)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Thesis/ORIGA_PRC_ROI/test/0/472.jpg: 224x224 0 0.84, 1 0.16, 2.8ms\n",
            "Speed: 1.8ms preprocess, 2.8ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 224)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Thesis/ORIGA_PRC_ROI/test/0/504.jpg: 224x224 1 0.71, 0 0.29, 2.9ms\n",
            "Speed: 1.9ms preprocess, 2.9ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 224)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Thesis/ORIGA_PRC_ROI/test/0/500.jpg: 224x224 1 0.94, 0 0.06, 3.0ms\n",
            "Speed: 2.1ms preprocess, 3.0ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 224)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Thesis/ORIGA_PRC_ROI/test/0/513.jpg: 224x224 1 0.86, 0 0.14, 2.9ms\n",
            "Speed: 2.0ms preprocess, 2.9ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 224)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Thesis/ORIGA_PRC_ROI/test/0/526.jpg: 224x224 1 0.96, 0 0.04, 4.1ms\n",
            "Speed: 2.2ms preprocess, 4.1ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 224)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Thesis/ORIGA_PRC_ROI/test/0/566.jpg: 224x224 1 1.00, 0 0.00, 2.9ms\n",
            "Speed: 2.0ms preprocess, 2.9ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 224)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Thesis/ORIGA_PRC_ROI/test/0/563.jpg: 224x224 0 1.00, 1 0.00, 2.8ms\n",
            "Speed: 1.7ms preprocess, 2.8ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 224)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Thesis/ORIGA_PRC_ROI/test/0/562.jpg: 224x224 1 0.91, 0 0.09, 2.9ms\n",
            "Speed: 2.0ms preprocess, 2.9ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 224)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Thesis/ORIGA_PRC_ROI/test/0/564.jpg: 224x224 1 0.92, 0 0.08, 3.1ms\n",
            "Speed: 2.4ms preprocess, 3.1ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 224)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Thesis/ORIGA_PRC_ROI/test/0/553.jpg: 224x224 0 0.98, 1 0.02, 3.3ms\n",
            "Speed: 2.1ms preprocess, 3.3ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 224)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Thesis/ORIGA_PRC_ROI/test/0/611.jpg: 224x224 1 0.85, 0 0.15, 3.1ms\n",
            "Speed: 2.2ms preprocess, 3.1ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 224)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Thesis/ORIGA_PRC_ROI/test/0/599.jpg: 224x224 1 0.87, 0 0.13, 2.9ms\n",
            "Speed: 2.1ms preprocess, 2.9ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 224)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Thesis/ORIGA_PRC_ROI/test/0/639.jpg: 224x224 0 0.97, 1 0.03, 3.1ms\n",
            "Speed: 2.4ms preprocess, 3.1ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 224)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Thesis/ORIGA_PRC_ROI/test/0/620.jpg: 224x224 1 1.00, 0 0.00, 2.9ms\n",
            "Speed: 2.0ms preprocess, 2.9ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 224)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Thesis/ORIGA_PRC_ROI/test/0/633.jpg: 224x224 1 1.00, 0 0.00, 2.8ms\n",
            "Speed: 1.7ms preprocess, 2.8ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 224)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Thesis/ORIGA_PRC_ROI/test/1/093.jpg: 224x224 1 1.00, 0 0.00, 3.9ms\n",
            "Speed: 2.6ms preprocess, 3.9ms inference, 0.1ms postprocess per image at shape (1, 3, 224, 224)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Thesis/ORIGA_PRC_ROI/test/1/087.jpg: 224x224 1 0.66, 0 0.34, 4.0ms\n",
            "Speed: 2.7ms preprocess, 4.0ms inference, 0.1ms postprocess per image at shape (1, 3, 224, 224)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Thesis/ORIGA_PRC_ROI/test/1/270.jpg: 224x224 0 0.95, 1 0.05, 3.8ms\n",
            "Speed: 2.5ms preprocess, 3.8ms inference, 0.1ms postprocess per image at shape (1, 3, 224, 224)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Thesis/ORIGA_PRC_ROI/test/1/301.jpg: 224x224 1 1.00, 0 0.00, 5.9ms\n",
            "Speed: 2.8ms preprocess, 5.9ms inference, 0.1ms postprocess per image at shape (1, 3, 224, 224)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Thesis/ORIGA_PRC_ROI/test/1/340.jpg: 224x224 1 0.99, 0 0.01, 8.0ms\n",
            "Speed: 2.9ms preprocess, 8.0ms inference, 0.1ms postprocess per image at shape (1, 3, 224, 224)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Thesis/ORIGA_PRC_ROI/test/1/402.jpg: 224x224 1 0.90, 0 0.10, 4.6ms\n",
            "Speed: 2.3ms preprocess, 4.6ms inference, 0.1ms postprocess per image at shape (1, 3, 224, 224)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Thesis/ORIGA_PRC_ROI/test/1/426.jpg: 224x224 1 1.00, 0 0.00, 3.0ms\n",
            "Speed: 2.1ms preprocess, 3.0ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 224)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Thesis/ORIGA_PRC_ROI/test/1/507.jpg: 224x224 1 1.00, 0 0.00, 2.7ms\n",
            "Speed: 2.0ms preprocess, 2.7ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 224)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Thesis/ORIGA_PRC_ROI/test/1/516.jpg: 224x224 1 1.00, 0 0.00, 2.8ms\n",
            "Speed: 1.7ms preprocess, 2.8ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 224)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Thesis/ORIGA_PRC_ROI/test/1/528.jpg: 224x224 1 0.99, 0 0.01, 3.0ms\n",
            "Speed: 2.3ms preprocess, 3.0ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 224)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Thesis/ORIGA_PRC_ROI/test/1/580.jpg: 224x224 0 0.99, 1 0.01, 3.1ms\n",
            "Speed: 2.5ms preprocess, 3.1ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 224)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Thesis/ORIGA_PRC_ROI/test/1/608.jpg: 224x224 0 0.76, 1 0.24, 3.7ms\n",
            "Speed: 1.7ms preprocess, 3.7ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 224)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Thesis/ORIGA_PRC_ROI/test/1/584.jpg: 224x224 1 1.00, 0 0.00, 3.9ms\n",
            "Speed: 2.1ms preprocess, 3.9ms inference, 0.1ms postprocess per image at shape (1, 3, 224, 224)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Thesis/ORIGA_PRC_ROI/test/1/640.jpg: 224x224 1 1.00, 0 0.00, 2.8ms\n",
            "Speed: 1.8ms preprocess, 2.8ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 224)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Thesis/ORIGA_PRC_ROI/test/1/636.jpg: 224x224 1 0.85, 0 0.15, 2.9ms\n",
            "Speed: 2.1ms preprocess, 2.9ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 224)\n",
            "Accuracy:  0.4307692307692308\n",
            "TP:  12\n",
            "TN:  16\n",
            "FP:  34\n",
            "FN:  3\n",
            "AUC score: 0.6586666666666667\n",
            " \n",
            "Loading for:  REFUGE_PRC\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Thesis/REFUGE_PRC_ROI/test/0/n0009.jpg: 224x224 1 0.80, 0 0.20, 3.2ms\n",
            "Speed: 2.6ms preprocess, 3.2ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 224)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Thesis/REFUGE_PRC_ROI/test/0/n0032.jpg: 224x224 1 0.84, 0 0.16, 2.9ms\n",
            "Speed: 1.9ms preprocess, 2.9ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 224)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Thesis/REFUGE_PRC_ROI/test/0/n0069.jpg: 224x224 0 1.00, 1 0.00, 3.0ms\n",
            "Speed: 2.2ms preprocess, 3.0ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 224)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Thesis/REFUGE_PRC_ROI/test/0/n0066.jpg: 224x224 1 0.88, 0 0.12, 3.0ms\n",
            "Speed: 1.9ms preprocess, 3.0ms inference, 0.1ms postprocess per image at shape (1, 3, 224, 224)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Thesis/REFUGE_PRC_ROI/test/0/n0074.jpg: 224x224 0 0.88, 1 0.12, 3.5ms\n",
            "Speed: 2.2ms preprocess, 3.5ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 224)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Thesis/REFUGE_PRC_ROI/test/0/n0086.jpg: 224x224 1 0.99, 0 0.01, 2.8ms\n",
            "Speed: 1.8ms preprocess, 2.8ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 224)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Thesis/REFUGE_PRC_ROI/test/0/n0094.jpg: 224x224 0 0.98, 1 0.02, 3.0ms\n",
            "Speed: 1.9ms preprocess, 3.0ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 224)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Thesis/REFUGE_PRC_ROI/test/0/n0088.jpg: 224x224 0 0.96, 1 0.04, 2.9ms\n",
            "Speed: 1.9ms preprocess, 2.9ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 224)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Thesis/REFUGE_PRC_ROI/test/0/n0117.jpg: 224x224 1 1.00, 0 0.00, 2.8ms\n",
            "Speed: 2.0ms preprocess, 2.8ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 224)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Thesis/REFUGE_PRC_ROI/test/0/n0116.jpg: 224x224 1 0.63, 0 0.37, 2.9ms\n",
            "Speed: 2.1ms preprocess, 2.9ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 224)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Thesis/REFUGE_PRC_ROI/test/0/n0137.jpg: 224x224 0 0.75, 1 0.25, 3.1ms\n",
            "Speed: 2.6ms preprocess, 3.1ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 224)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Thesis/REFUGE_PRC_ROI/test/0/n0155.jpg: 224x224 0 1.00, 1 0.00, 2.8ms\n",
            "Speed: 1.8ms preprocess, 2.8ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 224)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Thesis/REFUGE_PRC_ROI/test/0/n0172.jpg: 224x224 1 0.63, 0 0.37, 3.2ms\n",
            "Speed: 2.3ms preprocess, 3.2ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 224)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Thesis/REFUGE_PRC_ROI/test/0/n0168.jpg: 224x224 0 0.93, 1 0.07, 3.1ms\n",
            "Speed: 2.6ms preprocess, 3.1ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 224)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Thesis/REFUGE_PRC_ROI/test/0/n0187.jpg: 224x224 0 0.57, 1 0.43, 3.1ms\n",
            "Speed: 2.2ms preprocess, 3.1ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 224)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Thesis/REFUGE_PRC_ROI/test/0/n0197.jpg: 224x224 0 0.80, 1 0.20, 3.5ms\n",
            "Speed: 2.7ms preprocess, 3.5ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 224)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Thesis/REFUGE_PRC_ROI/test/0/n0196.jpg: 224x224 0 0.62, 1 0.38, 3.0ms\n",
            "Speed: 2.2ms preprocess, 3.0ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 224)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Thesis/REFUGE_PRC_ROI/test/0/n0223.jpg: 224x224 0 0.86, 1 0.14, 4.6ms\n",
            "Speed: 2.6ms preprocess, 4.6ms inference, 0.1ms postprocess per image at shape (1, 3, 224, 224)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Thesis/REFUGE_PRC_ROI/test/0/n0239.jpg: 224x224 0 0.88, 1 0.12, 4.1ms\n",
            "Speed: 3.0ms preprocess, 4.1ms inference, 0.1ms postprocess per image at shape (1, 3, 224, 224)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Thesis/REFUGE_PRC_ROI/test/0/n0248.jpg: 224x224 1 0.98, 0 0.02, 3.9ms\n",
            "Speed: 2.5ms preprocess, 3.9ms inference, 0.1ms postprocess per image at shape (1, 3, 224, 224)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Thesis/REFUGE_PRC_ROI/test/0/n0251.jpg: 224x224 1 0.73, 0 0.27, 4.9ms\n",
            "Speed: 2.7ms preprocess, 4.9ms inference, 0.1ms postprocess per image at shape (1, 3, 224, 224)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Thesis/REFUGE_PRC_ROI/test/0/n0279.jpg: 224x224 1 1.00, 0 0.00, 20.5ms\n",
            "Speed: 15.9ms preprocess, 20.5ms inference, 0.1ms postprocess per image at shape (1, 3, 224, 224)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Thesis/REFUGE_PRC_ROI/test/0/n0275.jpg: 224x224 0 0.76, 1 0.24, 3.0ms\n",
            "Speed: 2.3ms preprocess, 3.0ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 224)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Thesis/REFUGE_PRC_ROI/test/0/n0288.jpg: 224x224 0 0.94, 1 0.06, 2.9ms\n",
            "Speed: 2.0ms preprocess, 2.9ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 224)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Thesis/REFUGE_PRC_ROI/test/0/n0292.jpg: 224x224 0 0.81, 1 0.19, 3.0ms\n",
            "Speed: 2.2ms preprocess, 3.0ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 224)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Thesis/REFUGE_PRC_ROI/test/0/n0310.jpg: 224x224 0 0.78, 1 0.22, 3.2ms\n",
            "Speed: 2.5ms preprocess, 3.2ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 224)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Thesis/REFUGE_PRC_ROI/test/0/n0326.jpg: 224x224 0 0.99, 1 0.01, 3.0ms\n",
            "Speed: 2.1ms preprocess, 3.0ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 224)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Thesis/REFUGE_PRC_ROI/test/0/n0337.jpg: 224x224 0 0.90, 1 0.10, 2.8ms\n",
            "Speed: 1.9ms preprocess, 2.8ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 224)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Thesis/REFUGE_PRC_ROI/test/0/n0348.jpg: 224x224 1 1.00, 0 0.00, 3.1ms\n",
            "Speed: 2.9ms preprocess, 3.1ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 224)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Thesis/REFUGE_PRC_ROI/test/0/n0355.jpg: 224x224 1 1.00, 0 0.00, 2.9ms\n",
            "Speed: 1.9ms preprocess, 2.9ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 224)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Thesis/REFUGE_PRC_ROI/test/0/V0011.jpg: 224x224 1 0.73, 0 0.27, 2.9ms\n",
            "Speed: 2.1ms preprocess, 2.9ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 224)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Thesis/REFUGE_PRC_ROI/test/0/V0036.jpg: 224x224 0 0.88, 1 0.12, 3.1ms\n",
            "Speed: 2.3ms preprocess, 3.1ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 224)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Thesis/REFUGE_PRC_ROI/test/0/V0016.jpg: 224x224 0 0.92, 1 0.08, 2.9ms\n",
            "Speed: 1.9ms preprocess, 2.9ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 224)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Thesis/REFUGE_PRC_ROI/test/0/V0042.jpg: 224x224 0 1.00, 1 0.00, 2.7ms\n",
            "Speed: 1.7ms preprocess, 2.7ms inference, 0.1ms postprocess per image at shape (1, 3, 224, 224)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Thesis/REFUGE_PRC_ROI/test/0/V0037.jpg: 224x224 1 0.99, 0 0.01, 2.8ms\n",
            "Speed: 1.9ms preprocess, 2.8ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 224)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Thesis/REFUGE_PRC_ROI/test/0/V0043.jpg: 224x224 0 0.85, 1 0.15, 2.9ms\n",
            "Speed: 2.0ms preprocess, 2.9ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 224)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Thesis/REFUGE_PRC_ROI/test/0/V0067.jpg: 224x224 0 0.96, 1 0.04, 3.0ms\n",
            "Speed: 2.2ms preprocess, 3.0ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 224)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Thesis/REFUGE_PRC_ROI/test/0/V0061.jpg: 224x224 0 0.98, 1 0.02, 2.9ms\n",
            "Speed: 1.9ms preprocess, 2.9ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 224)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Thesis/REFUGE_PRC_ROI/test/0/V0082.jpg: 224x224 0 0.88, 1 0.12, 2.9ms\n",
            "Speed: 2.0ms preprocess, 2.9ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 224)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Thesis/REFUGE_PRC_ROI/test/0/V0102.jpg: 224x224 0 0.94, 1 0.06, 2.8ms\n",
            "Speed: 1.8ms preprocess, 2.8ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 224)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Thesis/REFUGE_PRC_ROI/test/0/V0126.jpg: 224x224 1 0.82, 0 0.18, 2.8ms\n",
            "Speed: 1.8ms preprocess, 2.8ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 224)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Thesis/REFUGE_PRC_ROI/test/0/V0142.jpg: 224x224 1 0.85, 0 0.15, 2.8ms\n",
            "Speed: 1.9ms preprocess, 2.8ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 224)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Thesis/REFUGE_PRC_ROI/test/0/V0131.jpg: 224x224 1 0.52, 0 0.48, 2.9ms\n",
            "Speed: 2.0ms preprocess, 2.9ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 224)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Thesis/REFUGE_PRC_ROI/test/0/V0135.jpg: 224x224 1 0.87, 0 0.13, 3.0ms\n",
            "Speed: 1.8ms preprocess, 3.0ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 224)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Thesis/REFUGE_PRC_ROI/test/0/V0144.jpg: 224x224 1 0.51, 0 0.49, 3.0ms\n",
            "Speed: 2.5ms preprocess, 3.0ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 224)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Thesis/REFUGE_PRC_ROI/test/0/V0161.jpg: 224x224 0 0.80, 1 0.20, 2.8ms\n",
            "Speed: 1.7ms preprocess, 2.8ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 224)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Thesis/REFUGE_PRC_ROI/test/0/V0150.jpg: 224x224 0 0.82, 1 0.18, 4.3ms\n",
            "Speed: 1.8ms preprocess, 4.3ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 224)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Thesis/REFUGE_PRC_ROI/test/0/V0156.jpg: 224x224 0 0.99, 1 0.01, 2.9ms\n",
            "Speed: 1.9ms preprocess, 2.9ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 224)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Thesis/REFUGE_PRC_ROI/test/0/V0179.jpg: 224x224 0 0.76, 1 0.24, 2.9ms\n",
            "Speed: 1.8ms preprocess, 2.9ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 224)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Thesis/REFUGE_PRC_ROI/test/0/V0174.jpg: 224x224 0 0.78, 1 0.22, 4.8ms\n",
            "Speed: 2.6ms preprocess, 4.8ms inference, 0.1ms postprocess per image at shape (1, 3, 224, 224)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Thesis/REFUGE_PRC_ROI/test/0/V0184.jpg: 224x224 0 0.99, 1 0.01, 2.9ms\n",
            "Speed: 1.9ms preprocess, 2.9ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 224)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Thesis/REFUGE_PRC_ROI/test/0/V0211.jpg: 224x224 0 0.69, 1 0.31, 4.1ms\n",
            "Speed: 2.6ms preprocess, 4.1ms inference, 0.1ms postprocess per image at shape (1, 3, 224, 224)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Thesis/REFUGE_PRC_ROI/test/0/V0192.jpg: 224x224 0 0.97, 1 0.03, 4.9ms\n",
            "Speed: 2.7ms preprocess, 4.9ms inference, 0.1ms postprocess per image at shape (1, 3, 224, 224)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Thesis/REFUGE_PRC_ROI/test/0/V0220.jpg: 224x224 1 0.78, 0 0.22, 4.0ms\n",
            "Speed: 2.7ms preprocess, 4.0ms inference, 0.1ms postprocess per image at shape (1, 3, 224, 224)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Thesis/REFUGE_PRC_ROI/test/0/V0231.jpg: 224x224 0 0.85, 1 0.15, 4.5ms\n",
            "Speed: 2.7ms preprocess, 4.5ms inference, 0.1ms postprocess per image at shape (1, 3, 224, 224)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Thesis/REFUGE_PRC_ROI/test/0/V0233.jpg: 224x224 0 0.93, 1 0.07, 3.1ms\n",
            "Speed: 2.2ms preprocess, 3.1ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 224)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Thesis/REFUGE_PRC_ROI/test/0/V0243.jpg: 224x224 1 0.69, 0 0.31, 3.0ms\n",
            "Speed: 2.5ms preprocess, 3.0ms inference, 0.1ms postprocess per image at shape (1, 3, 224, 224)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Thesis/REFUGE_PRC_ROI/test/0/V0255.jpg: 224x224 0 0.97, 1 0.03, 2.9ms\n",
            "Speed: 2.0ms preprocess, 2.9ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 224)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Thesis/REFUGE_PRC_ROI/test/0/V0236.jpg: 224x224 1 0.94, 0 0.06, 3.0ms\n",
            "Speed: 2.4ms preprocess, 3.0ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 224)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Thesis/REFUGE_PRC_ROI/test/0/V0239.jpg: 224x224 0 0.99, 1 0.01, 2.9ms\n",
            "Speed: 2.0ms preprocess, 2.9ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 224)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Thesis/REFUGE_PRC_ROI/test/0/V0263.jpg: 224x224 0 1.00, 1 0.00, 4.2ms\n",
            "Speed: 3.2ms preprocess, 4.2ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 224)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Thesis/REFUGE_PRC_ROI/test/0/V0265.jpg: 224x224 0 0.82, 1 0.18, 3.0ms\n",
            "Speed: 2.4ms preprocess, 3.0ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 224)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Thesis/REFUGE_PRC_ROI/test/0/V0284.jpg: 224x224 0 0.99, 1 0.01, 2.8ms\n",
            "Speed: 1.7ms preprocess, 2.8ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 224)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Thesis/REFUGE_PRC_ROI/test/0/V0281.jpg: 224x224 0 0.90, 1 0.10, 3.3ms\n",
            "Speed: 2.2ms preprocess, 3.3ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 224)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Thesis/REFUGE_PRC_ROI/test/0/V0298.jpg: 224x224 0 0.88, 1 0.12, 3.2ms\n",
            "Speed: 2.2ms preprocess, 3.2ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 224)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Thesis/REFUGE_PRC_ROI/test/0/V0315.jpg: 224x224 1 0.74, 0 0.26, 4.2ms\n",
            "Speed: 2.2ms preprocess, 4.2ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 224)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Thesis/REFUGE_PRC_ROI/test/0/V0314.jpg: 224x224 1 0.82, 0 0.18, 2.8ms\n",
            "Speed: 2.0ms preprocess, 2.8ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 224)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Thesis/REFUGE_PRC_ROI/test/0/V0308.jpg: 224x224 1 0.56, 0 0.44, 2.9ms\n",
            "Speed: 2.1ms preprocess, 2.9ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 224)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Thesis/REFUGE_PRC_ROI/test/0/V0327.jpg: 224x224 1 0.73, 0 0.27, 3.1ms\n",
            "Speed: 2.2ms preprocess, 3.1ms inference, 0.1ms postprocess per image at shape (1, 3, 224, 224)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Thesis/REFUGE_PRC_ROI/test/0/V0339.jpg: 224x224 0 0.99, 1 0.01, 2.9ms\n",
            "Speed: 1.8ms preprocess, 2.9ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 224)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Thesis/REFUGE_PRC_ROI/test/0/V0376.jpg: 224x224 0 1.00, 1 0.00, 2.9ms\n",
            "Speed: 1.9ms preprocess, 2.9ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 224)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Thesis/REFUGE_PRC_ROI/test/0/V0372.jpg: 224x224 0 0.73, 1 0.27, 2.8ms\n",
            "Speed: 1.8ms preprocess, 2.8ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 224)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Thesis/REFUGE_PRC_ROI/test/0/V0362.jpg: 224x224 0 0.64, 1 0.36, 2.9ms\n",
            "Speed: 2.2ms preprocess, 2.9ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 224)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Thesis/REFUGE_PRC_ROI/test/0/V0399.jpg: 224x224 1 1.00, 0 0.00, 2.9ms\n",
            "Speed: 2.1ms preprocess, 2.9ms inference, 0.1ms postprocess per image at shape (1, 3, 224, 224)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Thesis/REFUGE_PRC_ROI/test/1/g0009.jpg: 224x224 0 0.72, 1 0.28, 3.0ms\n",
            "Speed: 2.1ms preprocess, 3.0ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 224)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Thesis/REFUGE_PRC_ROI/test/1/g0028.jpg: 224x224 1 0.98, 0 0.02, 3.8ms\n",
            "Speed: 2.8ms preprocess, 3.8ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 224)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Thesis/REFUGE_PRC_ROI/test/1/V0032.jpg: 224x224 1 0.99, 0 0.01, 2.9ms\n",
            "Speed: 2.0ms preprocess, 2.9ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 224)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Thesis/REFUGE_PRC_ROI/test/1/V0028.jpg: 224x224 1 0.93, 0 0.07, 3.0ms\n",
            "Speed: 2.0ms preprocess, 3.0ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 224)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Thesis/REFUGE_PRC_ROI/test/1/V0160.jpg: 224x224 1 0.97, 0 0.03, 3.4ms\n",
            "Speed: 2.4ms preprocess, 3.4ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 224)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Thesis/REFUGE_PRC_ROI/test/1/V0242.jpg: 224x224 1 1.00, 0 0.00, 2.9ms\n",
            "Speed: 1.7ms preprocess, 2.9ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 224)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Thesis/REFUGE_PRC_ROI/test/1/V0333.jpg: 224x224 1 1.00, 0 0.00, 2.8ms\n",
            "Speed: 1.9ms preprocess, 2.8ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 224)\n",
            "Accuracy:  0.654320987654321\n",
            "TP:  6\n",
            "TN:  47\n",
            "FP:  27\n",
            "FN:  1\n",
            "AUC score: 0.8629343629343629\n",
            " \n",
            "Loading for:  RIM-ONE_PRC\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Thesis/RIM-ONE_PRC_ROI/test/0/r1_Im107.png: 224x224 0 1.00, 1 0.00, 3.1ms\n",
            "Speed: 2.2ms preprocess, 3.1ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 224)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Thesis/RIM-ONE_PRC_ROI/test/0/r1_Im006.png: 224x224 0 0.95, 1 0.05, 5.2ms\n",
            "Speed: 2.9ms preprocess, 5.2ms inference, 0.1ms postprocess per image at shape (1, 3, 224, 224)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Thesis/RIM-ONE_PRC_ROI/test/0/r2_Im140.png: 224x224 0 1.00, 1 0.00, 3.8ms\n",
            "Speed: 2.5ms preprocess, 3.8ms inference, 0.1ms postprocess per image at shape (1, 3, 224, 224)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Thesis/RIM-ONE_PRC_ROI/test/0/r2_Im116.png: 224x224 0 1.00, 1 0.00, 3.8ms\n",
            "Speed: 2.6ms preprocess, 3.8ms inference, 0.1ms postprocess per image at shape (1, 3, 224, 224)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Thesis/RIM-ONE_PRC_ROI/test/0/r2_Im158.png: 224x224 0 0.96, 1 0.04, 5.4ms\n",
            "Speed: 2.8ms preprocess, 5.4ms inference, 0.1ms postprocess per image at shape (1, 3, 224, 224)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Thesis/RIM-ONE_PRC_ROI/test/0/r2_Im166.png: 224x224 0 1.00, 1 0.00, 6.8ms\n",
            "Speed: 2.7ms preprocess, 6.8ms inference, 0.1ms postprocess per image at shape (1, 3, 224, 224)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Thesis/RIM-ONE_PRC_ROI/test/0/r1_Im072.png: 224x224 0 1.00, 1 0.00, 3.0ms\n",
            "Speed: 2.1ms preprocess, 3.0ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 224)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Thesis/RIM-ONE_PRC_ROI/test/0/r2_Im180.png: 224x224 0 1.00, 1 0.00, 2.9ms\n",
            "Speed: 1.8ms preprocess, 2.9ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 224)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Thesis/RIM-ONE_PRC_ROI/test/0/r2_Im206.png: 224x224 0 1.00, 1 0.00, 2.8ms\n",
            "Speed: 1.9ms preprocess, 2.8ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 224)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Thesis/RIM-ONE_PRC_ROI/test/0/r2_Im212.png: 224x224 0 1.00, 1 0.00, 2.8ms\n",
            "Speed: 1.8ms preprocess, 2.8ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 224)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Thesis/RIM-ONE_PRC_ROI/test/0/r3_N-53-L_left_half.png: 224x224 0 0.59, 1 0.41, 3.0ms\n",
            "Speed: 2.1ms preprocess, 3.0ms inference, 0.1ms postprocess per image at shape (1, 3, 224, 224)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Thesis/RIM-ONE_PRC_ROI/test/0/r3_N-87-L_left_half.png: 224x224 0 0.99, 1 0.01, 2.9ms\n",
            "Speed: 1.9ms preprocess, 2.9ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 224)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Thesis/RIM-ONE_PRC_ROI/test/0/r1_Im020.png: 224x224 0 1.00, 1 0.00, 3.0ms\n",
            "Speed: 2.0ms preprocess, 3.0ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 224)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Thesis/RIM-ONE_PRC_ROI/test/0/r1_Im059.png: 224x224 0 1.00, 1 0.00, 2.8ms\n",
            "Speed: 1.9ms preprocess, 2.8ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 224)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Thesis/RIM-ONE_PRC_ROI/test/0/r1_Im137.png: 224x224 0 0.86, 1 0.14, 2.9ms\n",
            "Speed: 1.8ms preprocess, 2.9ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 224)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Thesis/RIM-ONE_PRC_ROI/test/0/r1_Im156.png: 224x224 0 0.99, 1 0.01, 3.0ms\n",
            "Speed: 2.4ms preprocess, 3.0ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 224)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Thesis/RIM-ONE_PRC_ROI/test/0/r2_Im026.png: 224x224 0 1.00, 1 0.00, 2.9ms\n",
            "Speed: 2.0ms preprocess, 2.9ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 224)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Thesis/RIM-ONE_PRC_ROI/test/0/r2_Im030.png: 224x224 0 1.00, 1 0.00, 2.8ms\n",
            "Speed: 1.8ms preprocess, 2.8ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 224)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Thesis/RIM-ONE_PRC_ROI/test/0/r2_Im044.png: 224x224 0 0.99, 1 0.01, 2.8ms\n",
            "Speed: 1.8ms preprocess, 2.8ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 224)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Thesis/RIM-ONE_PRC_ROI/test/0/r2_Im084.png: 224x224 0 1.00, 1 0.00, 3.0ms\n",
            "Speed: 1.9ms preprocess, 3.0ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 224)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Thesis/RIM-ONE_PRC_ROI/test/0/r2_Im090.png: 224x224 0 1.00, 1 0.00, 2.9ms\n",
            "Speed: 2.0ms preprocess, 2.9ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 224)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Thesis/RIM-ONE_PRC_ROI/test/0/r2_Im104.png: 224x224 0 0.91, 1 0.09, 3.1ms\n",
            "Speed: 1.8ms preprocess, 3.1ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 224)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Thesis/RIM-ONE_PRC_ROI/test/0/r2_Im108.png: 224x224 0 1.00, 1 0.00, 2.9ms\n",
            "Speed: 2.0ms preprocess, 2.9ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 224)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Thesis/RIM-ONE_PRC_ROI/test/0/r2_Im114.png: 224x224 0 1.00, 1 0.00, 2.8ms\n",
            "Speed: 1.9ms preprocess, 2.8ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 224)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Thesis/RIM-ONE_PRC_ROI/test/0/r2_Im210.png: 224x224 0 1.00, 1 0.00, 2.8ms\n",
            "Speed: 1.7ms preprocess, 2.8ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 224)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Thesis/RIM-ONE_PRC_ROI/test/0/r2_Im230.png: 224x224 0 0.72, 1 0.28, 2.8ms\n",
            "Speed: 1.8ms preprocess, 2.8ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 224)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Thesis/RIM-ONE_PRC_ROI/test/0/r3_N-20-R_left_half.png: 224x224 0 1.00, 1 0.00, 2.9ms\n",
            "Speed: 1.8ms preprocess, 2.9ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 224)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Thesis/RIM-ONE_PRC_ROI/test/0/r3_N-3-L_left_half.png: 224x224 0 1.00, 1 0.00, 2.9ms\n",
            "Speed: 1.9ms preprocess, 2.9ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 224)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Thesis/RIM-ONE_PRC_ROI/test/0/r3_N-26-R_left_half.png: 224x224 0 1.00, 1 0.00, 2.9ms\n",
            "Speed: 1.9ms preprocess, 2.9ms inference, 0.1ms postprocess per image at shape (1, 3, 224, 224)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Thesis/RIM-ONE_PRC_ROI/test/0/r3_N-44-R_left_half.png: 224x224 0 0.98, 1 0.02, 2.8ms\n",
            "Speed: 2.4ms preprocess, 2.8ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 224)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Thesis/RIM-ONE_PRC_ROI/test/0/r3_N-69-L_left_half.png: 224x224 0 0.99, 1 0.01, 2.8ms\n",
            "Speed: 1.9ms preprocess, 2.8ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 224)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Thesis/RIM-ONE_PRC_ROI/test/0/r3_N-8-L_left_half.png: 224x224 0 0.99, 1 0.01, 2.7ms\n",
            "Speed: 1.7ms preprocess, 2.7ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 224)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Thesis/RIM-ONE_PRC_ROI/test/1/r2_Im287.png: 224x224 1 1.00, 0 0.00, 3.0ms\n",
            "Speed: 2.0ms preprocess, 3.0ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 224)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Thesis/RIM-ONE_PRC_ROI/test/1/r2_Im334.png: 224x224 1 1.00, 0 0.00, 3.8ms\n",
            "Speed: 2.9ms preprocess, 3.8ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 224)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Thesis/RIM-ONE_PRC_ROI/test/1/r2_Im416.png: 224x224 1 1.00, 0 0.00, 4.8ms\n",
            "Speed: 2.6ms preprocess, 4.8ms inference, 0.1ms postprocess per image at shape (1, 3, 224, 224)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Thesis/RIM-ONE_PRC_ROI/test/1/r3_S-10-R_left_half.png: 224x224 1 1.00, 0 0.00, 3.9ms\n",
            "Speed: 2.5ms preprocess, 3.9ms inference, 0.1ms postprocess per image at shape (1, 3, 224, 224)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Thesis/RIM-ONE_PRC_ROI/test/1/r2_Im339.png: 224x224 0 0.55, 1 0.45, 4.2ms\n",
            "Speed: 2.4ms preprocess, 4.2ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 224)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Thesis/RIM-ONE_PRC_ROI/test/1/r2_Im331.png: 224x224 0 0.61, 1 0.39, 4.8ms\n",
            "Speed: 2.8ms preprocess, 4.8ms inference, 0.1ms postprocess per image at shape (1, 3, 224, 224)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Thesis/RIM-ONE_PRC_ROI/test/1/r2_Im358.png: 224x224 1 1.00, 0 0.00, 3.0ms\n",
            "Speed: 2.1ms preprocess, 3.0ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 224)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Thesis/RIM-ONE_PRC_ROI/test/1/r2_Im383.png: 224x224 1 0.65, 0 0.35, 2.9ms\n",
            "Speed: 1.8ms preprocess, 2.9ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 224)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Thesis/RIM-ONE_PRC_ROI/test/1/r3_G-29-R_left_half.png: 224x224 1 1.00, 0 0.00, 4.6ms\n",
            "Speed: 2.3ms preprocess, 4.6ms inference, 0.1ms postprocess per image at shape (1, 3, 224, 224)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Thesis/RIM-ONE_PRC_ROI/test/1/r2_Im389.png: 224x224 1 1.00, 0 0.00, 3.0ms\n",
            "Speed: 2.3ms preprocess, 3.0ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 224)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Thesis/RIM-ONE_PRC_ROI/test/1/r2_Im449.png: 224x224 1 1.00, 0 0.00, 3.0ms\n",
            "Speed: 2.3ms preprocess, 3.0ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 224)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Thesis/RIM-ONE_PRC_ROI/test/1/r2_Im433.png: 224x224 1 1.00, 0 0.00, 4.5ms\n",
            "Speed: 2.4ms preprocess, 4.5ms inference, 0.1ms postprocess per image at shape (1, 3, 224, 224)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Thesis/RIM-ONE_PRC_ROI/test/1/r3_G-12-L_left_half.png: 224x224 1 1.00, 0 0.00, 3.0ms\n",
            "Speed: 2.1ms preprocess, 3.0ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 224)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Thesis/RIM-ONE_PRC_ROI/test/1/r3_G-31-R_left_half.png: 224x224 1 1.00, 0 0.00, 2.9ms\n",
            "Speed: 1.9ms preprocess, 2.9ms inference, 0.1ms postprocess per image at shape (1, 3, 224, 224)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Thesis/RIM-ONE_PRC_ROI/test/1/r3_S-18-L_left_half.png: 224x224 0 1.00, 1 0.00, 2.9ms\n",
            "Speed: 1.9ms preprocess, 2.9ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 224)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Thesis/RIM-ONE_PRC_ROI/test/1/r3_S-30-L_left_half.png: 224x224 1 0.93, 0 0.07, 2.9ms\n",
            "Speed: 2.0ms preprocess, 2.9ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 224)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Thesis/RIM-ONE_PRC_ROI/test/1/r3_S-32-L_left_half.png: 224x224 1 0.64, 0 0.36, 2.8ms\n",
            "Speed: 1.8ms preprocess, 2.8ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 224)\n",
            "Accuracy:  0.9387755102040817\n",
            "TP:  14\n",
            "TN:  32\n",
            "FP:  0\n",
            "FN:  3\n",
            "AUC score: 0.9632352941176471\n",
            " \n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}